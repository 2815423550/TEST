## hadoop集群的搭建

### 使用别人的虚拟机

```
1.首选打开虚拟机输入"ifconfig"查看虚拟机的ip地址
2.然后根据虚拟机的ip地址从而来修改你VMWare的虚拟网络VMnet8的虚拟子网地址、网关的ip
如：
虚拟机的ip地址、网关为：
[root@hadoop100 ~]# ifconfig
ens33: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 192.168.10.100  netmask 255.255.255.0  broadcast 192.168.10.255
        inet6 fe80::e468:a33c:7dfb:864f  prefixlen 64  scopeid 0x20<link>
        inet6 fe80::2179:c07e:e10c:be11  prefixlen 64  scopeid 0x20<link>
        ether 00:0c:29:0b:e8:36  txqueuelen 1000  (Ethernet)
        RX packets 144  bytes 31349 (30.6 KiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 121  bytes 20105 (19.6 KiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
```

```
于是：
编辑————虚拟网络编辑器————更改设置————VMnet8————子网ip：192.168.10.0————NAT设置————网关ip————192.168.10.2
```

然后：

![image-20221112200032442.png](https://s2.loli.net/2022/11/14/oaWygtvLKmPFX41.png) 

```
右键————打开“网络和Interent”设置————更改适配器选项————Interent协议4
```

![image-20221112200014028.png](https://s2.loli.net/2022/11/14/6HKqpbSEJrwsgfo.png) 

------





### 修改主机名

```
vim /etc/hostname
```

### 设置主机名称映射

主机名称映射：相当于把ip地址赋值给一个参数，以后用该参数即可替代ip地址，因为写ip地址很麻烦

```
vim /etc/hosts
```

```
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

192.168.10.100 hadoop100
192.168.10.101 hadoop101
192.168.10.102 hadoop102
192.168.10.103 hadoop103
192.168.10.104 hadoop104
192.168.10.105 hadoop105
192.168.10.106 hadoop106
192.168.10.107 hadoop107
192.168.10.108 hadoop108
```



### 设置虚拟机ip地址为静态：

```
vim /etc/sysconfig/network-scripts/ifcfg-ens33
```

```
TYPE="Ethernet"
PROXY_METHOD="none"
BROWSER_ONLY="no"
BOOTPROTO="static"
DEFROUTE="yes"
IPV4_FAILURE_FATAL="no"
IPV6INIT="yes"
IPV6_AUTOCONF="yes"
IPV6_DEFROUTE="yes"
IPV6_FAILURE_FATAL="no"
IPV6_ADDR_GEN_MODE="stable-privacy"
NAME="ens33"
UUID="5bddb733-eafd-4bd2-8867-3d88b0bded83"
DEVICE="ens33"
ONBOOT="yes"

IPADDR=192.168.10.100
GATEWAY=192.168.10.2
DNS1=192.168.10.2

```

```
这里的“dhcp”表示的是：动态获取ip地址，这使得每次虚拟机启动都会获得不同的ip地址
如果改成“static”，则表示为静态ip地址，不会改变
```



### 修改ip地址、网关、域名解析器

```
vim /etc/sysconfig/network-scripts/ifcfg-ens33
```

在末尾处添加：

```
IPADDR=192.168.10.100
GATEWAY=192.168.10.2
DNS1=192.168.10.2
```



### 重启虚拟机

设置ip地址后需要重启虚拟机才能生效

```
reboot
```

------







### 卸载虚拟机自带的JDK

```
rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps 
```

检查是否删完JDK

```
rpm -qa | grep -i java
```

这句命令的拓展：

```
#这句命令可以查看所有含“xxx”的文件，如查看所有含“java”的文件：
rpm -qa | grep -i java
所以这句命令可以用于检查是否安装了JDK
```

### 创建用户、修改用户密码

```apl
说明：
从（创建用户、修改用户密码————修改文件夹的所属主和所属组）这部分的作用是：
因为生产环境下我们码农都是没有root权限的，也不能使用root，所以需要这么做。但是我大概率不会去做这方面的码农，所以这部分的内容不建议这么快就开始学，可以先不学！！！
```

创建atguigu用户，并修改atguigu用户的密码（修改密码）

```
useradd root
passwd root
```

### 配置用户具有root权限

配置atguigu用户具有root权限，方便后期加sudo执行root权限的命令

```
 vim /etc/sudoers
```

修改/etc/sudoers文件，在%wheel这行下面添加一行，如下所示：

```
## Allow root to run any commands anywhere
root    ALL=(ALL)     ALL

## Allows people in group wheel to run all commands
%wheel  ALL=(ALL)       ALL
atguigu   ALL=(ALL)     NOPASSWD:ALL
```

### 修改文件夹的所属主和所属组

在/opt目录下创建文件夹，并修改所属主和所属组

（1）在/opt目录下创建module、software文件夹

```
mkdir /opt/module
mkdir /opt/software
```

（2）修改module、software文件夹的所有者和所属组均为atguigu用户 

```
chown atguigu:atguigu /opt/module 
chown atguigu:atguigu /opt/software
```

（3）查看module、software文件夹的所有者和所属组

```
cd /opt/
ll

如：
所属组 2 所属主 所属主 4096 5月  28 17:18 文件夹

总用量 12
drwxr-xr-x. 2 root    root    4096 9月   7 2017 rh
drwxr-xr-x. 2 atguigu atguigu 4096 5月  28 17:18 software
```

注意：：：从此开始都使用atguigu账号就行操作！！！！！



### 解压JDK

```
cd /opt/software

tar -zxvf JDK压缩包名字 -C JDK安装目录
如：tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/
```

### 配置JDK环境变量

```shell
新建（或打开）/etc/profile.d/my_env.sh文件（“my_env.sh”名字随便起，后缀名必须为sh，且必须放在/etc/profile.d目录下，因为在/etc/profile.d下的所有sh文件，在系统启动时会自动让这里的所有sh文件全局生效，环境变量一般都放在这个文件夹里，也就是my_env.sh）
vim /etc/profile.d/my_env.sh

添加如下内容：
#JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_212   （这里的/opt/module/jdk1.8.0_212是你JDK安装路径，这里的jdk1.8.0_212是在你解压JDK的时候系统自动给jdk的命名，你可以cd到你安装jdk的目录去ll查看一下）
export PATH=$PATH:$JAVA_HOME/bin

让新的环境变量PATH生效
source /etc/profile

测试JDK是否安装成功
java -version
```





### 解压hadoop

```
cd /opt/software

tar -zxvf JDK压缩包名字 -C hadoop安装目录
如：tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/
```

### 配置hadoop环境变量

```shell
vim /etc/profile.d/my_env.sh

#HADOOP_HOME
export HADOOP_HOME=hadoop安装路径(hadoop安装路径:cd /opt/module/  然后ll，赋值hadoop的名字，然后拼接上/opt/module/，这就是hadoop的安装路径，如：/opt/module/hadoop-3.1.3)
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin

让新的环境变量PATH生效
source /etc/profile

测试是否安装成功
hadoop version
```





###  克隆虚拟机

```
1.将虚拟机关机
2.要克隆的虚拟机上————右键————管理————克隆————当前状态————创建完整克隆
```

![image-20221112212106311.png](https://s2.loli.net/2022/11/14/ashGWkd3Lu91SUz.png) 

```
注意：
克隆的虚拟机的ip地址、主机名都是一样的，所以需要我们自己去手动修改
```

------





### 复制JDK、hadoop到其他服务器（已废弃）

```
scp -r 本地文件目录  用户名@主机名:存放的目录
[atguigu@hadoop100 hadoop]$ scp -r /opt/module/jdk1.8.0_212  root@hadoop101:/opt/module

[atguigu@hadoop100 hadoop]$ scp -r /opt/module/hadoop-3.1.3  root@hadoop101:/opt/module
```

首次连接会出现以下：

![image-20221114203033248](C:\Users\28154\AppData\Roaming\Typora\typora-user-images\image-20221114203033248.png)

```
输入yes，并输入密码即可
```





### 集群分发脚本xsync

```
#
[atguigu@hadoop100 hadoop]$ cd /home/atguigu

#
mkdir bin

#
cd bin

#
vim xsync
```

```shell
#!/bin/bash

#1. 判断参数个数
if [ $# -lt 1 ]
then
    echo Not Enough Arguement!
    exit;
fi

#2. 遍历集群所有机器
for host in hadoop100 hadoop101 hadoop102
do
    echo ====================  $host  ====================
    #3. 遍历所有目录，挨个发送

    for file in $@
    do
        #4. 判断文件是否存在
        if [ -e $file ]
            then
                #5. 获取父目录
                pdir=$(cd -P $(dirname $file); pwd)

                #6. 获取当前文件的名称
                fname=$(basename $file)
                ssh $host "mkdir -p $pdir"
                rsync -av $pdir/$fname $host:$pdir
            else
                echo $file does not exists!
        fi
    done
done
```

```
#
[atguigu@hadoop100 hadoop]$ chmod +x xsync

#
cp xsync /bin/

然后就可以使用了

#测试
xsync /home/atguigu/bin
如果不报错的话则说明成功了

同步集群jdk、hadoop配置文件
xsync /etc/profile.d/my_env.sh

让新的环境变量PATH生效
source /etc/profile
```





### 配置SSH免密登录

这里的要求：hadoop100以root用户给自身在内的三台虚拟机ssh；hadoop的三台虚拟机都各自以atguigu的身份给自身在内的三台虚拟机ssh；（注意，以root的用户的时候需要ssh-keygen -t rsa生成公钥私钥，以atguigu用户的时候也需要需要ssh-keygen -t rsa生成公钥私钥）也就是说：三台虚拟机都以root用户生成公钥私钥，以atguigu用户的时候也需要重新生成公钥私钥

```
生成公钥私钥
ssh-keygen -t rsa	按三次enter键
```

![image-20221113114556881.png](https://s2.loli.net/2022/11/14/UTwtHDY36zZhOKj.png)

出现以上界面说明成功生成公钥私钥

```
# 查看公钥和私钥
cd /root/.ssh
# 私钥
cat id_rsa
# 公钥
cat id_rsa.pub
```

然后，下面命令即为该服务器免密登录到hadoop101服务器：（注意，先在机器上生成公钥私钥之后才能执行下面这句代码，否则会出现错误）

![image-20221113120444293.png](https://s2.loli.net/2022/11/14/CRfW5IAzPjcn4X1.png) 

```
ssh-copy-id hadoop101
```

切换服务器：

```
ssh hadoop101
```

回到原服务器：

```
exit
```

查看本服务器运行哪些服务器免密访问：

```
cd /root/.ssh

cat authorized_keys
```

------

------

------





### 配置集群——配置文件

一般情况下，按照下面配置来配：

|      | hadoop100            | hadoop101                    | hadoop102                       |
| ---- | -------------------- | ---------------------------- | ------------------------------- |
| HDFS | NameNode    DataNode | DataNode                     | SecondaryNameNode      DataNode |
| YARN | NodeManager          | ResourceManager  NodeManager | NodeManager                     |

```
[atguigu@hadoop100 hadoop]$ cd $HADOOP_HOME/etc/hadoop
```

```xml
# 配置core-site.xml
vim core-site.xml

<configuration>
    <!-- 指定NameNode的地址 -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop100:8020</value>
    </property>

    <!-- 指定hadoop数据的存储目录 -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-3.1.3/data</value>
    </property>
</configuration>
```

```xml
# 配置hdfs-site.xml
vim hdfs-site.xml

<configuration>
	<!-- NameNode web端访问地址-->
	<property>
        <name>dfs.namenode.http-address</name>
        <value>hadoop100:9870</value>
    </property>
	<!-- SecondaryNameNode web端访问地址-->
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop102:9868</value>
    </property>
</configuration>
```

```xml
# 配置yarn-site.xml
vim yarn-site.xml

<configuration>
    <!-- 指定MR走shuffle -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>

    <!-- 指定ResourceManager的地址-->
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop101</value>
    </property>

    <!-- 环境变量的继承 -->
    <property>
        <name>yarn.nodemanager.env-whitelist</name>     			       <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
    
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>2048</value>
 	</property>
    
 	<property>
        <name>yarn.nodemanager.resource.cpu-vcores</name>
        <value>2</value>
 	</property>

	<property>
    	<name>yarn.nodemanager.vmem-check-enabled</name>
    	<value>false</value>
	</property>
</configuration>

```

```xml
# 配置mapred-site.xml
vim mapred-site.xml

<configuration>
	<!-- 指定MapReduce程序运行在Yarn上 -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

然后以atguigu用户在所有的机器上ssh都互相ssh，以root用户在hadoop100ssh所有的其他的机器和自身

```
同步其他机器上的$HADOOP_HOME/etc/hadoop目录
[atguigu@hadoop100 hadoop]$ xsync  $HADOOP_HOME/etc/hadoop
```



### 配置集群——配置主机名

```
[atguigu@hadoop100 hadoop]$ vim /opt/module/hadoop-3.1.3/etc/hadoop/workers
```

添加集群的主机名，如：（注意该文件里不允许有空格或空行！）

```
hadoop100
hadoop101
hadoop102
```

然后同步所有节点：

```
[atguigu@hadoop100 hadoop]$ xsync /opt/module/hadoop-3.1.3/etc
```





### 配置集群——启动集群

格式化之前：

```
1.确保所有节点的/opt/module/hadoop-3.1.3目录下文件的归属者为atguigu，确保所有节点的当前用户为atguigu，如下图：
```

```
[root@hadoop100 hadoop-3.1.3]# ll
总用量 40844
drwxr-xr-x. 2 atguigu atguigu      183 9月  12 2019 bin
drwxrwxr-x. 4 atguigu atguigu       37 11月 14 13:09 data
drwxr-xr-x. 3 atguigu atguigu       20 9月  12 2019 etc
drwxr-xr-x. 2 atguigu atguigu      106 9月  12 2019 include
drwxr-xr-x. 3 atguigu atguigu       20 9月  12 2019 lib
drwxr-xr-x. 4 atguigu atguigu      288 9月  12 2019 libexec
-rw-rw-r--. 1 atguigu atguigu   147145 9月   4 2019 LICENSE.txt
drwxrwxr-x. 3 atguigu atguigu     4096 11月 16 19:21 logs
-rw-rw-r--. 1 atguigu atguigu    21867 9月   4 2019 NOTICE.txt
-rw-rw-r--. 1 atguigu atguigu     1366 9月   4 2019 README.txt
drwxr-xr-x. 3 atguigu atguigu     4096 9月  12 2019 sbin
drwxr-xr-x. 4 atguigu atguigu       31 9月  12 2019 share
```

![image-20221114120124941.png](https://s2.loli.net/2022/11/14/ViuDdz5aNKHqUCP.png)

![image-20221114120148273.png](https://s2.loli.net/2022/11/14/ARMkE7gIsljoaOL.png)

首次启动集群需要初始化：

```
[atguigu@hadoop100 hadoop]$ cd /opt/module/hadoop-3.1.3
hdfs namenode -format
```

初始化完毕之后，在/opt/module/hadoop-3.1.3目录下如果有这两个目录则说明初始化成功！

![image-20221114120246584.png](https://s2.loli.net/2022/11/14/gvW1klE9NdXa2AC.png)

（注意：初始化完成之后，只有hadoop100节点存在data、logs目录，其他节点都没有；在执行完sbin/start-dfs.sh命令后其他的节点才存在logs目录，但是依然没有data目录。）

```
[atguigu@hadoop100 hadoop]$ cd /opt/module/hadoop-3.1.3
sbin/start-dfs.sh

[atguigu@hadoop101 hadoop]$ cd /opt/module/hadoop-3.1.3
sbin/start-yarn.sh
```

以下为成功启动hdfs集群：

 ![image-20221114132048692.png](https://s2.loli.net/2022/11/14/fXyljxDqdmtOuH2.png)

![image-20221114132056178.png](https://s2.loli.net/2022/11/14/9i8yc7pem1r2ojP.png) 

![image-20221114132106744.png](https://s2.loli.net/2022/11/14/sDWioPE6bpvcXzZ.png) 





### 启动集群时遇到的失败

```
问题：启动集群时提示权限不够

原因：这是因为你的hadoop101、hadoop102的/opt/module/hadoop-3.1.3文件夹的所属主和所属组都不是atguigu

解法：使用该代码把所属主和所属组改成atguigu
sudo chown -R atguigu:atguigu /opt/module/hadoop-3.1.3/ 
```

![image-20221114092431771.png](https://s2.loli.net/2022/11/14/7UuIv892nbQcByC.png) 

------

```
未知错误
```

![image-20221114093127916.png](https://s2.loli.net/2022/11/14/OLsMkHYVhKcql56.png) 

------

```
问题：启动dfs时没有启动datanode

原因：

解法：未知
```

------

```
问题：All keys were skipped because they already exist on the remote system./usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed

/usr/bin/ssh-copy-id: WARNING: All keys were skipped because they already exist on the remote system.
		(if you think this is a mistake, you may want to use -f option)

原因：未生成公钥私钥就开始ssh-copy-id
```



------

```xml
问题：启动时没有nodemanager，不报错，且有其他

原因：nodemanager的配置文件错了

解法：cd $HADOOP_HOME/etc/hadoop
vim hdfs-site.xml
写成这样：
<configuration>
	<!-- NameNode web端访问地址-->
	<property>
        <name>dfs.namenode.http-address</name>
        <value>hadoop100:9870</value>
    </property>
	<!-- SecondaryNameNode web端访问地址-->
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop102:9868</value>
    </property>
    <!-- 下面这个2048可以改，根据你要运行的程序大小来定义-->
    <property>
    	<name>yarn.nodemanager.resource.memory-mb</name>
    	<value>2048</value>
	</property> 
	<!-- 下面的“2”是你机器的cpu核数，查看cpu核数命令：cat /proc/cpuinfo| grep "cpu cores"| uniq-->
	<property>
    	<name>yarn.nodemanager.resource.cpu-vcores</name>
    	<value>2</value>
 	</property>
</configuration>
```



------

```
问题：启动dfs时没有启动secondnamenode

原因：未知

解法：未知
```



------

```
问题：Failed to start OpenSSH Server daemon
或者：Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).

原因：ssh免密登录没配置好

解法：以root用户在hadoop101对本机和其他机器进行ssh；以atguigu用户在所有机器上对本机和其他机器进行ssh；
```

![image-20221113161556119](C:\Users\28154\AppData\Roaming\Typora\typora-user-images\image-20221113161556119.png) 

------

```
问题：集群没有namenode，有其他

原因：格式化的时候出了问题

解法：
1.停止集群
[atguigu@hadoop100 hadoop]$ cd /opt/module/hadoop-3.1.3
sbin/stop-dfs.sh

2.删除每个机器上的data、logs
rm -rf data/ logs/

3. 来到NameNode节点上格式化NameNode
hdfs namenode -format

4.重新启动集群
sbin/start-dfs.sh
```

------

```
问题：初始化集群时说权限不够

原因、解法：你来到错误的节点了，初始化集群工作应该去到hadoop100(存放namenode的节点)上
```

![image-20221114092651346.png](https://s2.loli.net/2022/11/14/cxD9asEveoAPVqr.png)

------

```
问题：Attempting to operate on hdfs namenode as root

原因：你以root用户启动集群了

解法：切换成普通用户，如：su atguigu
```

![image-20221113192550076.png](https://s2.loli.net/2022/11/14/nY9ibW2S5j8sQpN.png)

------

```
问题：集群启动后访问页面无法访问

解法：把主机名换成ip地址即可
```

![image-20221113195503507.png](https://s2.loli.net/2022/11/14/ajXgRihS3dY9Ium.png)

![image-20221113195624381.png](https://s2.loli.net/2022/11/14/SxfW3GsrLlA42KM.png)

------





### hadoop集群启停脚本

```
[atguigu@hadoop100 ~]$ cd /home/atguigu/bin
vim myhadoop.sh
```

输入以下内容：

```shell
#!/bin/bash

if [ $# -lt 1 ]
then
    echo "No Args Input..."
    exit ;
fi

case $1 in
"start")
        echo " =================== 启动 hadoop集群 ==================="

        echo " --------------- 启动 hdfs ---------------"
        ssh hadoop100 "/opt/module/hadoop-3.1.3/sbin/start-dfs.sh"
        echo " --------------- 启动 yarn ---------------"
        ssh hadoop101 "/opt/module/hadoop-3.1.3/sbin/start-yarn.sh"
        echo " --------------- 启动 historyserver ---------------"
        ssh hadoop100 "/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver"
;;
"stop")
        echo " =================== 关闭 hadoop集群 ==================="

        echo " --------------- 关闭 historyserver ---------------"
        ssh hadoop100 "/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver"
        echo " --------------- 关闭 yarn ---------------"
        ssh hadoop101 "/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh"
        echo " --------------- 关闭 hdfs ---------------"
        ssh hadoop100 "/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh"
;;
*)
    echo "Input Args Error..."
;;
esac
```

```
[atguigu@hadoop100 hadoop]$ sudo chmod 777 myhadoop.sh

sudo cp myhadoop.sh /bin/
```

然后就可以使用了，使用命令：

```
hadoop集群集体停止：
[atguigu@hadoop100 hadoop]$ myhadoop.sh stop

myhadoop.sh start
```

![image-20221114134702964.png](https://s2.loli.net/2022/11/14/kbOyLHVT9mvjfwE.png) 





### 查看三台服务器JPS进程脚本

```
[atguigu@hadoop100 ~]$ cd /home/atguigu/bin
vim jpsall
```

```shell
#!/bin/bash

for host in hadoop100 hadoop101 hadoop102
do
        echo =============== $host ===============
        ssh $host jps 
done
```

```
chmod 777 jpsall

cp jpsall /bin/

xsync /home/atguigu/bin/

然后去到每一个节点下：cp jpsall /bin/

使用方法：输入“jpsall”即可查看所有节点的jps进程
```

![image-20221114140355449.png](https://s2.loli.net/2022/11/14/tAOaVJDS5FUqbBk.png) 

```
使用方法：
jpsall
```



### 配置历史服务器

```
[atguigu@hadoop100 hadoop]$ cd $HADOOP_HOME/etc/hadoop

vim mapred-site.xml
```

加上：

```xml
<!-- 历史服务器端地址 -->
<property>
    <name>mapreduce.jobhistory.address</name>
    <value>hadoop100:10020</value>
</property>

<!-- 历史服务器web端地址 -->
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop100:19888</value>
</property>
```

把mapred-site.xml同步到其他节点：

```
xsync $HADOOP_HOME/etc/hadoop/mapred-site.xml
```

重启resourcemanager、nodemanagers

```
# 来到你安装resourcemanager、nodemanagers的节点(本实验中为hadoop101)：
[atguigu@hadoop101 hadoop]$ cd /opt/module/hadoop-3.1.3
sbin/stop-yarn.sh

# 重新启动
sbin/start-yarn.sh
```

```
[atguigu@hadoop100 hadoop]$ cd /opt/module/hadoop-3.1.3
bin/mapred --daemon start historyserver
```

成功后页面：

```
[atguigu@hadoop100 hadoop-3.1.3]$ jps
11698 Jps
11636 JobHistoryServer
4760 NameNode
11422 NodeManager
10031 DataNode
```

访问hadoop100:19888可查看：

![image-20221113212323351.png](https://s2.loli.net/2022/11/14/qMvtJreO8VFlPCI.png)



### 配置日志的聚集（可不做）

```
[atguigu@hadoop100 hadoop]$ cd $HADOOP_HOME/etc/hadoop

vim yarn-site.xml
```

```xml
<!-- 开启日志聚集功能 -->
<property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
</property>
<!-- 设置日志聚集服务器地址 -->
<property>  
    <name>yarn.log.server.url</name>  
    <value>http://hadoop100:19888/jobhistory/logs</value>
</property>
<!-- 设置日志保留时间为7天 -->
<property>
    <name>yarn.log-aggregation.retain-seconds</name>
    <value>604800</value>
</property>
```

```
[atguigu@hadoop100 hadoop]$ xsync $HADOOP_HOME/etc/hadoop/yarn-site.xml
```

```
# 关闭NodeManager 、ResourceManager和HistoryServer
[atguigu@hadoop101 hadoop-3.1.3]$ cd /opt/module/hadoop-3.1.3
sbin/stop-yarn.sh
[atguigu@hadoop100 ~]$ mapred --daemon stop historyserver

# 启动NodeManager 、ResourceManage和HistoryServer
[atguigu@hadoop101 ~]$ cd /opt/module/hadoop-3.1.3/etc/hadoop
start-yarn.sh
[atguigu@hadoop100 ~]$ mapred --daemon start historyserver
```



### 集群同步时间

```
[atguigu@hadoop100 ~]$ sudo systemctl start ntpd
sudo systemctl is-enabled ntpd
```

![image-20221114143537519](C:\Users\28154\AppData\Roaming\Typora\typora-user-images\image-20221114143537519.png) 

```
sudo systemctl status ntpd
```

![image-20221114143557277](C:\Users\28154\AppData\Roaming\Typora\typora-user-images\image-20221114143557277.png) 

```
sudo vim /etc/ntp.conf
```

```
修改一：去掉注释
把 #restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap 

修改为：
restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap
```

```properties
修改二：注释以下代码
server 0.centos.pool.ntp.org iburst
server 1.centos.pool.ntp.org iburst
server 2.centos.pool.ntp.org iburst
server 3.centos.pool.ntp.org iburst

修改为：
#server 0.centos.pool.ntp.org iburst
#server 1.centos.pool.ntp.org iburst
#server 2.centos.pool.ntp.org iburst
#server 3.centos.pool.ntp.org iburst
```

```
修改三：添加以下代码
server 127.127.1.0
fudge 127.127.1.0 stratum 10
```

```
修改四：
sudo vim /etc/sysconfig/ntpd

添加以下内容：
SYNC_HWCLOCK=yes
```

```
修改五：
重新启动ntpd服务
sudo systemctl start ntpd

设置ntpd服务开机启动
sudo systemctl enable ntpd
```

```
修改六：
在其他机器配置1分钟与时间服务器同步一次：（想让哪个机器与hadoop100时间同步就写哪个）
[atguigu@hadoop101 ~]$ sudo crontab -e
或者 [atguigu@hadoop102 ~]$ sudo crontab -e

编写定时任务如下：（“1”表示每隔一分钟与“hadoop100”时间同步）
*/1 * * * * /usr/sbin/ntpdate hadoop100
```

------

------

------

------

------

## wordCount案例

### 创建maven项目

### 创建 log4j.properties

```properties
log4j.rootLogger=INFO, stdout  
log4j.appender.stdout=org.apache.log4j.ConsoleAppender  
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout  
log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n  
log4j.appender.logfile=org.apache.log4j.FileAppender  
log4j.appender.logfile.File=target/spring.log  
log4j.appender.logfile.layout=org.apache.log4j.PatternLayout  
log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n
```

### 引入依赖

```xml
    <dependencies>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-client</artifactId>
            <version>3.1.3</version>
        </dependency>
        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <version>4.12</version>
        </dependency>
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-log4j12</artifactId>
            <version>1.7.30</version>
        </dependency>
    </dependencies>

<build>
        <plugins>
            <plugin>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.6.1</version>
                <configuration>
                    <source>1.8</source>
                    <target>1.8</target>
                </configuration>
            </plugin>
            <plugin>
                <artifactId>maven-assembly-plugin</artifactId>
                <configuration>
                    <descriptorRefs>
                        <descriptorRef>jar-with-dependencies</descriptorRef>
                    </descriptorRefs>
                </configuration>
                <executions>
                    <execution>
                        <id>make-assembly</id>
                        <phase>package</phase>
                        <goals>
                            <goal>single</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
</build>
```

### 创建WordCountDriver （唯一需要改动的地方）

```java
import java.io.IOException;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WordCountDriver {

    public static void main(String[] args) throws IOException,
            ClassNotFoundException, InterruptedException {

        // 1 获取配置信息以及获取job对象
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf);

        // 2 关联本Driver程序的jar
        job.setJarByClass(WordCountDriver.class);

        // 3 关联Mapper和Reducer的jar
        job.setMapperClass(WordCountMapper.class);
        job.setReducerClass(WordCountReducer.class);

        // 4 设置Mapper输出的kv类型
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(IntWritable.class);

        // 5 设置最终输出kv类型
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        // 6 设置输入和输出路径;args[0]表示传进来的第一个参数，args[1]表示传进来的第二个参数
        FileInputFormat.setInputPaths(job, new Path("要统计单词的文件"));
        FileOutputFormat.setOutputPath(job, new Path("统计结束后输出的路径"));

        // 7 提交job
        boolean result = job.waitForCompletion(true);
        System.exit(result ? 0 : 1);
    }
}
```

### 创建WordCountMapper

```java
import java.io.IOException;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class WordCountMapper extends Mapper<LongWritable, Text, Text, IntWritable>{

    Text k = new Text();
    IntWritable v = new IntWritable(1);

    @Override
    protected void map(LongWritable key, Text value, Context context)
            throws IOException, InterruptedException {

        // 1 获取一行
        String line = value.toString();

        // 2 切割
        String[] words = line.split(" ");

        // 3 输出
        for (String word : words) {

            k.set(word);
            context.write(k, v);
        }
    }
}
```

### 创建WordCountReducer

```java
import java.io.IOException;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class WordCountReducer extends Reducer<Text, IntWritable, Text, IntWritable>{

    int sum;
    IntWritable v = new IntWritable();

    @Override
    protected void reduce(Text key, Iterable<IntWritable> values,Context context)
            throws IOException, InterruptedException {

        // 1 累加求和
        sum = 0;
        for (IntWritable count : values) {
            sum += count.get();
        }

        // 2 输出
        v.set(sum);
        context.write(key,v);
    }
}
```

### 本机上运行：前往WordCountDriver，启动

以下是启动成功页面

![image-20221114164255752.png](https://s2.loli.net/2022/11/14/gVn5JpANZjQ7fxk.png)

### 前往你输出的文件夹，用Typora打开 part-r-00000 文件，即可看到单词统计结果

![image-20221114164446786.png](https://s2.loli.net/2022/11/14/PEyLXO7hau2nQNF.png)

### 在本机上本地上打包，然后上传到集群hadoop100的/opt/module/hadoop-3.1.3

![image-20221114175756797.png](https://s2.loli.net/2022/11/14/ZJWDQOh3kHyERUw.png)

### 打开浏览器

```
打开浏览器 http://192.168.10.100:9870/ ，确保根目录下有input目录，确保根目录下没有output目录

打开浏览器 http://192.168.10.101:8088/ ，注意观察程序运行过程
```

### 正式启动

```
在/opt/module/hadoop-3.1.3下，执行 “hadoop jar wordCount-1.0-SNAPSHOT.jar com.atguigu.mapreduce.wordcount.WordCountDriver /input /output”

	wordCount-1.0-SNAPSHOT-jar-with-dependencies.jar 

代码解读：hadoop jar jar包名称 Driver程序的全类名 输入路径 输出路径
```



### 常见错误

```
Invalid resource request, requested resource type=[memory-mb] < 0 or greater than maximum allowed allocation.
```

![image-20221115102806600](C:\Users\28154\AppData\Roaming\Typora\typora-user-images\image-20221115102806600.png)

```
原因：nodemanager所允许的运行内存为1024M，你该程序大小为1536

解法：
去到每台机器上：cd $HADOOP_HOME/etc/hadoop
vim yarn-site.xml
修改yarn.nodemanager.resource.memory-mb的value为2048
```

### 成功运行结果

![image.png](https://s2.loli.net/2022/11/15/OpUebRzA2J6PSQu.png)

![image-20221115105023015.png](https://s2.loli.net/2022/11/15/xuVL64ktmcwaqUn.png)

![image-20221115104747029.png](https://s2.loli.net/2022/11/15/pD8Lv7a6WA9RBEb.png) 

------

------

------

------

------

## 基础知识



### 虚拟机分区

```
/boot :启动虚拟机时所需要的空间，一般1G
swap  :当内存不够用时会使用磁盘的空间来充当内存，这里的就是改用来充当内存的磁盘空间，一般4G
/	  :根目录，一般用完剩余的
```



### 查看主机名称

```
hostname
```



### 重启虚拟机

```
reboot
```



### 查看当前路径

```
pwd
```



### 切换用户

```
su 用户名
如，su root
```



### 停止进程

如：

```
Another app is currently holding the yum lock; waiting for it exit...
.....
.....
.......，进程ID为：3030
```

我们只需要根据进程ID，来停止该进程就可以了

```
kill -9 3030
```



### 安装 epel-release

作用：？？？埋雷

```
yum install -y epel-release
```



### 安装 vim

```
yum install -y vim
```



### 安装 net-tool

```
yum install -y net-tools
```



### 关闭防火墙

```
systemctl stop firewalld

#开机时自动关闭防火墙
systemctl disable firewalld.service
```



### 查看防火墙状态

```
systemctl status firewalld 
```



### 保存文件时，如果出现

![image-20221112210254415.png](https://s2.loli.net/2022/11/14/36QcV2897ZNOnfi.png) 

```
表示必须得强制保存，运行 "wq!" 即可
```



### 查看该目录下所有文件（可以查看隐藏文件）

```
ls -al
```



### 浏览器查看文件的页面的打开方法

![image-20221113195905346.png](https://s2.loli.net/2022/11/14/9mtCFdEnGNkOHQ4.png)

```
此页面的打开方法：
```

![image-20221113195925748.png](https://s2.loli.net/2022/11/14/6yOBumUnpkW8IFZ.png) 



### hdfs上无法创建文件夹

```
Permission denied: user=dr.who, access=WRITE, inode="/":atguigu:supergroup:drwxr-xr-x
```

![image-20221114175547025.png](https://s2.loli.net/2022/11/14/8dhOPk7Uil6qDs2.png)

```
解决办法：
hadoop fs -chmod -R 777 /
```



### 提示权限不够

![image-20221113205046832.png](https://s2.loli.net/2022/11/14/5CDrWNbSfHGQXM8.png) 

```
在命令前加上 sudo
```



### XShell连接不上虚拟机

```
一定不是XShell的问题，可能是虚拟机的SSH出了问题，例如：Failed to start OpenSSH Server daemon
```



### 解压压缩包时出现错误

```
解法：把“-zxvf”改成“-xvf”

[root@hadoop100 software]# tar -zxvf mysql-5.7.29-1.el7.x86_64.rpm-bundle.tar -C /opt/module

gzip: stdin: not in gzip format
tar: Child returned status 1
tar: Error is not recoverable: exiting now
```





------

------

------

------

------

## zookeeper集群的搭建

（基于hadoop集群的搭建）

### zookeeper的安装

```
[atguigu@hadoop100 hadoop]$ cd /opt/software
查看是否有zookeeper安装包

解压（安装）到/opt/module/
tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz -C /opt/module/

重命名
cd /opt/module/
mv apache-zookeeper-3.5.7-bin apache-zookeeper-3.5.7
```

```
修改配置文件:

1.重命名
mv zoo_sample.cfg zoo.cfg

2.创建用来存储zookeeper数据的文件夹
cd /opt/module/apache-zookeeper-3.5.7
mkdir zkData
cd zkData
pwd
最后出来的是：/opt/module/apache-zookeeper-3.5.7/zkData
然后复制该路径

3.修改配置文件
vim zoo.cfg
把dataDir=/tmp/zookeeper改成/opt/module/apache-zookeeper-3.5.7/zkData

cd /opt/module/apache-zookeeper-3.5.7/bin
vim zkEnv.sh
添加上：JAVA_HOME="/opt/module/jdk1.8.0_212"
```

```
cd /opt/module/apache-zookeeper-3.5.7
启动zookeeper服务端：
sudo bin/zkServer.sh start

启动zookeeper客户端：
sudo bin/zkCli.sh

输入 ls /		，如果出现以下界面则说明安装成功。
```

![image-20221114214732919.png](https://s2.loli.net/2022/11/15/lKnP27EXGsbVixd.png)



### 新增myid文件

```
cd /opt/module/apache-zookeeper-3.5.7/zkData
sudo vim myid
写入相对应的标识，如hadoop100机器上就写人 0 ，hadoop101就写如 1 
```



### 分发到其他节点

```
cd /opt/module
xsync apache-zookeeper-3.5.7
```



### 修改其他节点的myid

```
hadoop100机器上就写人 0 ，hadoop101就写如 1 以此类推...
```



### 修改配置文件

```
cd /opt/module/apache-zookeeper-3.5.7/conf

sudo vim zoo.cfg
```

```properties
server.0=hadoop100:2888:3888
server.1=hadoop101:2888:3888
server.2=hadoop102:2888:3888
```

```
分发配置文件到其他节点：
xsync zoo.cfg
```



### 启动zookeeper集群

```
# 前往hadoop100、hadoop101、hadoop102：
cd /opt/module/apache-zookeeper-3.5.7
sudo bin/zkServer.sh start

# 查看状态
sudo bin/zkServer.sh status

# 停止
sudo bin/zkServer.sh stop
```



### 启动zookeeper集群时遇到的错误

![image-20221115112553974.png](https://s2.loli.net/2022/11/15/vh7etVgMEZIrTOi.png) 

```
执行 sudo bin/zkServer.sh status 时报错，这是因为集群启动未过半，例如三台服务器需要启动至少两台才能成功启动zookeeper集群。
```



### zookeeper启停脚本

```
cd /home/atguigu/bin

sudo vim zk.sh
```

```shell
#!/bin/bash
case $1 in
"start"){
for i in hadoop100 hadoop101 hadoop102
do
 echo ---------- zookeeper $i 启动 ------------
ssh $i "/opt/module/apache-zookeeper-3.5.7/bin/zkServer.sh start"
done
};;
"stop"){
for i in hadoop100 hadoop101 hadoop102
do
 echo ---------- zookeeper $i 停止 ------------ 
ssh $i "/opt/module/apache-zookeeper-3.5.7/bin/zkServer.sh stop"
done
};;
"status"){
for i in hadoop100 hadoop101 hadoop102
do
 echo ---------- zookeeper $i 状态 ------------ 
ssh $i "/opt/module/apache-zookeeper-3.5.7/bin/zkServer.sh status"
done
};;
esac
```

```
# 赋予权限
sudo chmod 777 zk.sh

sudo cp zk.sh /bin/

xsync /home/atguigu/bin/

# 启动zookeeper集群
zk.sh start

# 查看zookeeper集群状态
zk.sh status

# 停止zookeeper集群
zk.sh stop
```



### 常见错误

```
错误一：
```

```
Usage: /opt/module/apache-zookeeper-3.5.7/bin/zkServer.sh [--config <conf-dir>] {start|start-foreground|stop|restart|status|print-cmd}
bash: start: command not found
```

![image-20221115115527489.png](https://s2.loli.net/2022/11/15/hdilNuDvwKoAxqU.png)

```
sudo chown -R atguigu:atguigu /opt/module/apache-zookeeper-3.5.7/zkData
```



```
错误二：
```

```
Starting zookeeper ... FAILED TO START
```

```
描述：即无论怎么做都是无法开启
解法：未知解法，反正我睡一觉它就好了。。。
```



```
错误三：
```

```
描述：启动zookeeper时显示Starting zookeeper ... STARTED，但是jps的时候发现并没有QuorumPeerMain，这其实说明zookeeper并没有成功启动。

解法：前往zookeeper安装目录下的存放data数据的文件夹：
cd /opt/module/apache-zookeeper-3.5.7/zkData
```

![image-20221115134324424.png](https://s2.loli.net/2022/11/15/urhnpJ9EONLoizD.png) 

```
如图，可以看到有version-2，把version-2删除：
sudo rm -rf version-2

再次重新启动，以下界面即为成功启动zookeeper：
```

![image-20221115134447753.png](https://s2.loli.net/2022/11/15/UPK8p6VfCgtEviI.png) 

------

------

------

------

------

## HBase集群的搭建

### 安装

```
[atguigu@hadoop100 hadoop]$ cd /opt/software

tar -zxvf hbase-2.4.11-bin.tar.gz -C /opt/module

sudo vim /etc/profile.d/my_env.sh
```

```
#HBASE_HOME
export HBASE_HOME=/opt/module/hbase-2.4.11
export PATH=$PATH:$HBASE_HOME/bin
```

```
分发环境变量配置文件
sudo xsync /etc/profile.d/my_env.sh

使环境变量配置文件失效
source /etc/profile
```



### 修改hbase-site.xml 

```
[atguigu@hadoop100 hadoop]$ cd /opt/module/hbase-2.4.11/conf

vim hbase-site.xml 
改成下面这样：
```

```xml
<configuration>
	<property>
    	<name>hbase.cluster.distributed</name>
    	<value>true</value>
  	</property>

    <property>
 		<name>hbase.zookeeper.quorum</name>
 		<value>hadoop100,hadoop101,hadoop102</value>
 		<description>The directory shared by RegionServers.</description>
	</property>
	<property>
 		<name>hbase.rootdir</name>
 		<value>hdfs://hadoop100:8020/hbase</value>
 		<description>The directory shared by RegionServers.</description>
 	</property>
</configuration>
```



### 修改regionservers

```
[atguigu@hadoop100 hadoop]$ cd /opt/module/hbase-2.4.11/conf
vim regionservers
```

```
hadoop100
hadoop101
hadoop102
```



```
cd /opt/module/hbase-2.4.11/lib/client-facing-thirdparty

mv slf4j-reload4j-1.7.33.jar slf4j-reload4j-1.7.33.jar.bak
```



### 分发整个HBase文件夹

```
[atguigu@hadoop100 hadoop]$ cd /opt/module
xsync hbase-2.4.11
```



### 启动

```
[atguigu@hadoop100 hadoop]$ start-hbase.sh
```

![image-20221115162834872](C:\Users\28154\AppData\Roaming\Typora\typora-user-images\image-20221115162834872.png)

 成功启动截图：（启动顺序：myhadoop.sh start ——> zk.sh start ——> start-hbase.sh ）

![image-20221115164920974](C:\Users\28154\AppData\Roaming\Typora\typora-user-images\image-20221115164920974.png) 

访问 http://192.168.10.100:16010/ 可以出现以下界面：

![image-20221115165242925](C:\Users\28154\AppData\Roaming\Typora\typora-user-images\image-20221115165242925.png)

------

------

------

------

------

## Hive的安装与部署

（本实验基于hadoop集群基础上）



### 安装hive

```shell
#解压
tar -zxvf /opt/software/apache-hive-3.1.2-bin.tar.gz -C /opt/module/

#重命名
cd /opt/module 
mv apache-hive-3.1.2-bin hive-3.1.2

#避免日志冲突
cd /opt/module/hive-3.1.2 
rm -rf lib/guava-19.0.jar
cp /opt/module/hadoop-3.1.3/share/hadoop/common/lib/guava-27.0-jre.jar /opt/module/hive-3.1.2/lib

#配置环境变量
sudo vim /etc/profile.d/my_env.sh
```

```shell
#HIVE_HOME
export HIVE_HOME=/opt/module/hive-3.1.2
export PATH=$PATH:$HIVE_HOME/bin
```

```shell
#使环境变量生效
source /etc/profile.d/my_env.sh

#初始化元数据库
cd /opt/module/hive-3.1.2 
bin/schematool -dbType derby -initSchema
```



### 修改配置文件

```
cd /opt/module/hive-3.1.2/conf
sudo vim hive-site.xml
```

```xml
<configuration>
<!-- 存储元数据mysql相关配置 -->
<property>
	<name>javax.jdo.option.ConnectionURL</name>
	<value>jdbc:mysql://hadoop100:3306/hive3?createDatabaseIfNotExist=true&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8</value>
</property>

<property>
	<name>javax.jdo.option.ConnectionDriverName</name>
	<value>com.mysql.jdbc.Driver</value>
</property>

<property>
	<name>javax.jdo.option.ConnectionUserName</name>
	<value>root</value>
</property>

<property>
	<name>javax.jdo.option.ConnectionPassword</name>
	<value>hadoop</value>
</property>

<!-- H2S运行绑定host -->
<property>
    <name>hive.server2.thrift.bind.host</name>
    <value>hadoop100</value>
</property>

<!-- 远程模式部署metastore metastore地址 -->
<property>
    <name>hive.metastore.uris</name>
    <value>thrift://hadoop100:9083</value>
</property>

<!-- 关闭元数据存储授权  --> 
<property>
    <name>hive.metastore.event.db.notification.api.auth</name>
    <value>false</value>
</property>
</configuration>

```



### 启动hive

```shell
#一定要按照以下步骤：

#启动hadoop集群：
myhadoop.sh start

#启动hive：
hive

#hive启动成功页面
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/module/hive-3.1.2/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = a3a73cf8-8e90-4541-8992-0e998885fdff

Logging initialized using configuration in jar:file:/opt/module/hive-3.1.2/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive> 

#常见错误(1)：
Exception in thread "main" java.lang.RuntimeException: com.ctc.wstx.exc.WstxParsingException: Unexpected character combination '</' in epilog (extra close tag?).
 at [row,col,system-id]: [47,2,"file:/opt/module/hive-3.1.2/conf/hive-site.xml"]
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3024)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2973)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2848)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:1460)
	at org.apache.hadoop.hive.conf.HiveConf.getVar(HiveConf.java:4996)
	at org.apache.hadoop.hive.conf.HiveConf.getVar(HiveConf.java:5069)
	at org.apache.hadoop.hive.conf.HiveConf.initialize(HiveConf.java:5156)
	at org.apache.hadoop.hive.conf.HiveConf.<init>(HiveConf.java:5099)
	at org.apache.hadoop.hive.common.LogUtils.initHiveLog4jCommon(LogUtils.java:97)
	at org.apache.hadoop.hive.common.LogUtils.initHiveLog4j(LogUtils.java:81)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:699)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:683)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
Caused by: com.ctc.wstx.exc.WstxParsingException: Unexpected character combination '</' in epilog (extra close tag?).
 at [row,col,system-id]: [47,2,"file:/opt/module/hive-3.1.2/conf/hive-site.xml"]
	at com.ctc.wstx.sr.StreamScanner.constructWfcException(StreamScanner.java:621)
	at com.ctc.wstx.sr.StreamScanner.throwParseError(StreamScanner.java:491)
	at com.ctc.wstx.sr.StreamScanner.throwParseError(StreamScanner.java:475)
	at com.ctc.wstx.sr.BasicStreamReader.nextFromProlog(BasicStreamReader.java:2149)
	at com.ctc.wstx.sr.BasicStreamReader.closeContentTree(BasicStreamReader.java:2991)
	at com.ctc.wstx.sr.BasicStreamReader.nextFromTree(BasicStreamReader.java:2734)
	at com.ctc.wstx.sr.BasicStreamReader.next(BasicStreamReader.java:1123)
	at org.apache.hadoop.conf.Configuration$Parser.parseNext(Configuration.java:3320)
	at org.apache.hadoop.conf.Configuration$Parser.parse(Configuration.java:3114)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3007)
	... 17 more
	
解法:你的hive-site.xml配置文件出错了



#常见错误(2):
[atguigu@hadoop100 software]$ hive
Caused by: java.net.ConnectException: Call From hadoop100/192.168.10.100 to hadoop100:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused

原因：没有开启HDFS



#常见错误(3)：
[atguigu@hadoop100 software]$ hive
ame node is in safe mode.

解法：hadoop dfsadmin -safemode leave



#未知错误(4)：
hive> show databases;
FAILED: HiveException java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient



#未知错误(5)：
启动hive后出现一大堆日志



#未知错误(6)：
[atguigu@hadoop100 software]$ hive
Host 'hadoop100' is not allowed to connect to this MySQL server



#未知错误(7)：
[atguigu@hadoop100 software]$ hive	或者 hive> show databases;
Required table missing : "VERSION" in Catalog "" Schema "". DataNucleus requires this table to perform its persistence operations. Either your MetaData is incorrect, or you need to enable "datanucleus.schema.autoCreateTables"


```

------

------

------

------

------

## MySQL的安装与部署

### 安装MySQL

```shell
#解压
cd /opt/module
sudo mkdir mysql
cd /opt/software
sudo tar -xvf mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar -C /opt/module/mysql

#安装依赖
sudo yum -y install libaio
cd /opt/module/mysql

sudo rpm -ivh mysql-community-common-5.7.28-1.el7.x86_64.rpm mysql-community-libs-5.7.28-1.el7.x86_64.rpm mysql-community-client-5.7.28-1.el7.x86_64.rpm mysql-community-server-5.7.28-1.el7.x86_64.rpm 

#以下即为安装成功：
[atguigu@hadoop100 mysql]$ sudo rpm -ivh mysql-community-common-5.7.28-1.el7.x86_64.rpm mysql-community-libs-5.7.28-1.el7.x86_64.rpm mysql-community-client-5.7.28-1.el7.x86_64.rpm mysql-community-server-5.7.28-1.el7.x86_64.rpm 
警告：mysql-community-common-5.7.28-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY
准备中...                          ################################# [100%]
	软件包 mysql-community-common-5.7.28-1.el7.x86_64 已经安装
	软件包 mysql-community-libs-5.7.28-1.el7.x86_64 已经安装
	软件包 mysql-community-client-5.7.28-1.el7.x86_64 已经安装
	软件包 mysql-community-server-5.7.28-1.el7.x86_64 已经安装
	

#常见错误：
[root@hadoop100 software]# tar -zxvf mysql-5.7.29-1.el7.x86_64.rpm-bundle.tar -C /opt/module
gzip: stdin: not in gzip format
tar: Child returned status 1
tar: Error is not recoverable: exiting now

解法：把“-zxvf”改成“-xvf”
```



### 初始化mysql

```shell
mysqld --initialize

#常见错误(1)：
[root@hadoop100 lib]# mysqld --initialize
2022-11-16T12:41:58.081814Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).
2022-11-16T12:41:58.084027Z 0 [ERROR] --initialize specified but the data directory has files in it. Aborting.
2022-11-16T12:41:58.084060Z 0 [ERROR] Aborting

原因：已经初始化过了，可以不管，直接下一步



#未知错误(2)：
[atguigu@hadoop100 mysql]$ mysqld --initialize
mysqld: Can't create directory '/var/lib/mysql/' (Errcode: 17 - File exists)
2022-11-16T10:45:20.229134Z 0 [Warning] Changed limits: max_open_files: 1024 (requested 5000)
2022-11-16T10:45:20.229345Z 0 [Warning] Changed limits: table_open_cache: 431 (requested 2000)
2022-11-16T10:45:20.229485Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).
2022-11-16T10:45:20.232136Z 0 [ERROR] Aborting
```



### 更改mysql的所属组和所属主

```shell
chown mysql:mysql /var/lib/mysql -R

查看mysql密码：
sudo cat  /var/log/mysqld.log
如：[Note] A temporary password is generated for root@localhost: #这里的便是密码
```



### 设置MySQL密码

```shell
mysql -u root -p
Enter password:     #这里输入在日志中生成的临时密码

#更新root密码  设置为hadoop
mysql> alter user user() identified by "123456";

#授权
mysql> use mysql;

mysql> GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123456' WITH GRANT OPTION;

mysql> FLUSH PRIVILEGES; 


#常见错误(1)：
mysql> alter user user() identified by "000000";
ERROR 1819 (HY000): Your password does not satisfy the current policy requirements

解法：
第一步：mysql> set global validate_password_policy=0;
Query OK, 0 rows affected (0.00 sec)

第二步（设置密码长度）：mysql> set global validate_password_length=6;
Query OK, 0 rows affected (0.00 sec)

然后即可修改密码，如：mysql> alter user user() identified by "123456";
Query OK, 0 rows affected (0.01 sec)



#常见错误(2)：
mysql> use mysql;
ERROR 1820 (HY000): You must reset your password using ALTER USER statement before executing this statement.

解法：你必须先去更改MySQL密码



#未知错误(3)：
[atguigu@hadoop100 root]$ mysql -u root -p
Enter password: （输入了正确的密码）
ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (111)


#未知错误(4):
mysql> alter user user() identified by "hadoop";
ERROR 29 (HY000): File './mysql/user.MYD' not found (Errcode: 13 - Permission denied)
```



### 启动MySQL

```shell
#mysql的启动和关闭
systemctl stop mysqld
systemctl status mysqld
systemctl start mysqld

#设置MySQL为开机自启动服务
systemctl enable  mysqld

#查看是否已经设置自启动成功
systemctl list-unit-files | grep mysqld
#以下为成功设置开机自启动：
mysqld.service                                enabled 
```



------

------

------

------

------

## 伴生资料

```
资料使用说明：
想重新开始学的用阶段一，想免去前面麻烦步骤又想自己搭建集群的去阶段二，想直接用成品的去阶段三

阶段一使用：
跟着《集群的搭建》一步一步做

阶段二使用：
从《配置集群——启动集群》开始

阶段三使用：
切记不可格式化namenode，启动虚拟机后，每台虚拟机都切换成atguigu用户，然后再hadoop100虚拟机里 
cd /opt/module/hadoop-3.1.3		然后执行myhadoop.sh start 集群便会启动，最后执行 jpsall查看启动结果
```

### 集群的搭建阶段一：

原虚拟机

链接: https://pan.baidu.com/s/15svKOSSbkuGsXck2lNZaZQ 	提取码: 1111 



### 集群的搭建阶段二：

已经安装jdk、hadoop、ip地址修改等的三台虚拟机

链接：https://pan.baidu.com/s/1CiHUX27vNdAyivE3HBpZ4g 	提取码：1111 




### 集群的搭建阶段三：

已成功运行的集群

链接：https://pan.baidu.com/s/1rRUmnyPTyK_4LMN3teQ2jA 	提取码：1111 



### CentOS-7-x86_64光盘：

链接：https://pan.baidu.com/s/1qs9jhH9seRPeW89cvO2iIg 	提取码：1111 



### hadoop-3.1.3安装包：

链接：https://pan.baidu.com/s/1rNV3Rk1caq7wr_VhC_4qJg 	提取码：1111 



### jdk1.8-linux版：

链接：https://pan.baidu.com/s/1LXjCGsw7XvRUjtNyC5DwJg 	提取码：1111 



### zookeeper-apache-3.5.7：

链接：https://pan.baidu.com/s/1WaY2OT7jZnmVkCcKoTxtOg 	提取码：1111 



### VMware-workstation-15.5：

链接：https://pan.baidu.com/s/1sI1ybeft9gDGxsim7g-0zw 	提取码：1111 



### mysql-5.7.29-64位：

链接：https://pan.baidu.com/s/12p2-gj54ZRbFZkrAIFwRfw 	提取码：1111 



### hbase-2.4.11：

链接：https://pan.baidu.com/s/1J-OhCV0bzrYRF9wok1Zhng 	提取码：1111 



### hive-3.1.2：

链接：https://pan.baidu.com/s/1jVRRElFcBdQPGGIhdbSBGQ 	提取码：1111 
